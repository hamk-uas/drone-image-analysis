{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387c0065",
   "metadata": {},
   "source": [
    "# Train an anti-aliased U-net based GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a29f76",
   "metadata": {},
   "source": [
    "## Imports and GPU identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy import special\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "from datetime import datetime\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.config.experimental.get_memory_info(\"/device:GPU:0\")['current'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99069d54",
   "metadata": {},
   "source": [
    "## Test Keras convolution\n",
    "Find out what the Keras convolution automatic zero paddings are for padding = \"SAME\", depending on the input size and kernel size. For skip connections it is important that the data stays centered spatially. These tests need not be run for the rest of the notebook to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downsampling, even size input, even size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 8, 8, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((4, 4, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 2, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = input_, filters = kernel, strides = 2, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"The output is properly centered.\")\n",
    "print(\"Output size = input size / 2\")\n",
    "\n",
    "print(\"\\nDownsampling, odd size input, even size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 7, 7, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((4, 4, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 2, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = input_, filters = kernel, strides = 2, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"Invalid output centering! Don't do this.\")\n",
    "\n",
    "print(\"\\nDownsampling, even size input, odd size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 8, 8, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((3, 3, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 2, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = input_, filters = kernel, strides = 1, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"Invalid output centering! Don't do this.\")\n",
    "\n",
    "print(\"\\nDownsampling, odd size input, odd size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 9, 9, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((5, 5, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 2, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = input_, filters = kernel, strides = 1, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"The output is properly centered.\")\n",
    "print(\"Output size = (input size + 1) / 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upsampling, any size input, even size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 4, 4, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "tile = tf.constant([[0, 0], [0, 4]], dtype=tf.float32)\n",
    "input_shape = input_.get_shape()\n",
    "tiles = tf.reshape(tf.tile(tile, [input_shape[-3], input_shape[-2]]), (1, input_shape[-3]*2, input_shape[-2]*2, 1))\n",
    "print(\"Diluted:\")\n",
    "diluted = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation='nearest')(input_)*tiles\n",
    "print(diluted[0, :, :, 0].numpy());\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((4, 4, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 1, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = diluted, filters = kernel, strides = 1, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"The output is properly centered.\")\n",
    "print(\"Output size = input size * 2\")\n",
    "\n",
    "print(\"\\nUpsampling, any size input, odd size kernel:\")\n",
    "print(\"Input:\")\n",
    "input_ = tf.ones((1, 4, 4, 1), dtype=tf.float32)\n",
    "print(input_[0, :, :, 0].numpy())\n",
    "tile = tf.constant([[0, 0], [0, 4]], dtype=tf.float32)\n",
    "input_shape = input_.get_shape()\n",
    "tiles = tf.reshape(tf.tile(tile, [input_shape[-3], input_shape[-2]])[1:,1:], (1, input_shape[-3]*2 - 1, input_shape[-2]*2 - 1, 1))\n",
    "print(\"Diluted:\")\n",
    "diluted = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation='nearest')(input_)[:,1:,1:,:]*tiles\n",
    "print(diluted[0, :, :, 0].numpy());\n",
    "print(\"Kernel:\")\n",
    "kernel = tf.ones((3, 3, 1, 1), dtype=tf.float32)\n",
    "print(kernel[:, :, 0, 0].numpy())\n",
    "print(\"Output of strides = 1, padding = 'SAME' convolution:\")\n",
    "conv = tf.nn.conv2d(input = diluted, filters = kernel, strides = 1, padding = 'SAME')\n",
    "print(conv[0, :, :, 0].numpy())\n",
    "print(\"The output is properly centered.\")\n",
    "print(\"Output size = input size * 2 - 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53594bd",
   "metadata": {},
   "source": [
    "## Circularly symmetric low-pass or anti-aliasing filter\n",
    "Functions for generating a filter kernel with a parameterized cutoff frequency and kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e996b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_lowpass_kernel(omega_c, N):  # omega = cutoff frequency in radians (pi is max), N = horizontal size of the kernel, also its vertical size.\n",
    "    with np.errstate(divide='ignore',invalid='ignore'):    \n",
    "        kernel = np.fromfunction(lambda x, y: omega_c*special.j1(omega_c*np.sqrt((x - (N - 1)/2)**2 + (y - (N - 1)/2)**2))/(2*np.pi*np.sqrt((x - (N - 1)/2)**2 + (y - (N - 1)/2)**2)), [N, N])\n",
    "    if N % 2:\n",
    "        kernel[(N - 1)//2, (N - 1)//2] = omega_c**2/(4*np.pi)\n",
    "    return kernel\n",
    "\n",
    "def rotated_cosine_window(N):  # N = horizontal size of the targeted kernel, also its vertical size, must be odd.\n",
    "    return np.fromfunction(lambda y, x: np.maximum(np.cos(np.pi/2*np.sqrt(((x - (N - 1)/2)/((N - 1)/2 + 1))**2 + ((y - (N - 1)/2)/((N - 1)/2 + 1))**2)), 0), [N, N])\n",
    "\n",
    "def windowed_circular_lowpass_kernel(cutoff, kernel_size):\n",
    "    return (circular_lowpass_kernel(cutoff, kernel_size)*rotated_cosine_window(kernel_size)).astype(np.float32);\n",
    "\n",
    "def test_kernel(kernel):\n",
    "    kernel_size = kernel.shape[0] #height, should be same as width\n",
    "    \n",
    "    print(\"Kernel:\")\n",
    "    plt.imshow(kernel, vmin=-0.25, vmax=0.25, cmap='bwr', extent=[-kernel_size/2, kernel_size/2, -kernel_size/2, kernel_size/2])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Frequency response:\")\n",
    "    freq_resp = np.abs(np.fft.fftshift(np.fft.fft2(np.roll(np.pad(kernel, 101, mode = 'constant', constant_values = 0), shift = (-kernel_size//2-99, -kernel_size//2-99), axis = (0, 1)))))\n",
    "    plt.imshow(freq_resp, vmin=-1.2, vmax=1.2, cmap='bwr', extent=[-np.pi, np.pi, -np.pi, np.pi])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c89670",
   "metadata": {},
   "source": [
    "## Load training target images and low-pass filter them\n",
    "\n",
    "Note: Do NOT use the filtered PNG images as network input, because they have been quantized. They can be saved for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "oversampling = 2  # Oversampling factor, 2 is a good choice\n",
    "aa_even_kernel_size = 12 # Size of even sized antialiasing filter\n",
    "aa_odd_kernel_size = aa_even_kernel_size + 1 # Size of odd sized antialiasing filter\n",
    "approx_batch_size = 4\n",
    "train_image_cropped_size = 256\n",
    "photos_dir = \"C:/Users/romat/Desktop/anotherfolder\"\n",
    "save_filtered_photos_dir = \"D:/roman/filtered_grass_images_subset\" # save folder, or None to disable saving\n",
    "\n",
    "print(\"Even size kernel:\")\n",
    "test_kernel(windowed_circular_lowpass_kernel(np.pi/oversampling, aa_even_kernel_size))\n",
    "print(\"Odd size kernel:\")\n",
    "test_kernel(windowed_circular_lowpass_kernel(np.pi/oversampling, aa_odd_kernel_size))\n",
    "\n",
    "def channeled_kernel(kernel_prototype, num_channels):\n",
    "    kernel_expanded = tf.expand_dims(kernel_prototype, 2)\n",
    "    kernel_repeated = tf.repeat(kernel_expanded, num_channels, axis=2)\n",
    "    return tf.expand_dims(kernel_repeated, -1)\n",
    "\n",
    "def load_and_filter_image(filepath, channeled_kernel):\n",
    "    image = tf.io.decode_png(tf.io.read_file(filepath), channels=3, dtype=tf.dtypes.uint8)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32) * 2 - 1\n",
    "    image = tf.nn.depthwise_conv2d([image], channeled_kernel, [1, 1, 1, 1], \"VALID\")[0]\n",
    "    if save_filtered_photos_dir is not None:\n",
    "        basename = tf.py_function(lambda string_tensor: os.path.basename(string_tensor.numpy()), [filepath], tf.string)\n",
    "        tf.io.write_file(save_filtered_photos_dir + \"/\" + basename, tf.io.encode_png(tf.image.convert_image_dtype((image + 1)/2, dtype=tf.dtypes.uint8, saturate=True)))\n",
    "    return image\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files(\"C:/Users/romat/Desktop/anotherfolder/*.png\")\n",
    "print(train_dataset)\n",
    "train_dataset = train_dataset.map(lambda filepath: load_and_filter_image(filepath, channeled_kernel(windowed_circular_lowpass_kernel(np.pi/oversampling, aa_even_kernel_size), 3)), num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "train_dataset = train_dataset.cache() # Load photos now instead of doing it again for each copy made in the next line\n",
    "train_dataset = train_dataset.repeat(tf.math.floordiv(approx_batch_size, train_dataset.cardinality()))\n",
    "train_dataset = train_dataset.cache()\n",
    "\n",
    "batch_size = train_dataset.cardinality() # batch size\n",
    "print(\"Batch size = \" + str(batch_size.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba26b3d",
   "metadata": {},
   "source": [
    "## Isotropic lowpass filtering layers\n",
    "These layers apply a circularly symmmetrical lowpass filter. They preserve spatial centering of the data to facilitate skip connections and center cropping in the network.\n",
    "\n",
    "`IsotropicLowpassFilterLayer` accepts `strides = 1` to preserve the feature map size and `strides = 2` to downsample it to half size. With `strides = 1`, the kernel size must be odd. With downsampling, only even input and kernel sizes are supported, resulting in even-sized output. `cutoff` is the cutoff frequency (before downsampling).\n",
    "\n",
    "`IsotropicLowpassFilteredUpsampleLayer` doubles the spatial size of the feature map. `cutoff` is the cutoff frequency after upsampling. `kernel_size` must be even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a334bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsotropicLowpassFilterLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, cutoff, kernel_size, strides = 1):\n",
    "        super(IsotropicLowpassFilterLayer, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides        \n",
    "        assert self.strides == 1 or self.strides == 2, \"Accepted values for strides are 1 and 2. Tuples or arrays are not accepted.\"\n",
    "        if self.strides == 1:\n",
    "            assert self.kernel_size % 2 == 1, \"kernel_size must be odd when strides = 1\"\n",
    "        if self.strides == 2:\n",
    "            assert self.kernel_size % 2 == 0, \"kernel_size must be even when strides = 2\"\n",
    "        \n",
    "        self.kernel_prototype = windowed_circular_lowpass_kernel(cutoff, self.kernel_size)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.filtering = tf.keras.layers.DepthwiseConv2D(self.kernel_size, trainable=False, use_bias=False, padding='same', strides=self.strides, weights=[channeled_kernel(self.kernel_prototype, input_shape[-1])])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.filtering(inputs)\n",
    "\n",
    "def get_upsample_multiplication_tensor(input_shape):\n",
    "    tile = tf.constant([[0, 0], [0, 4]], dtype=tf.float32)\n",
    "    return tf.reshape(tf.tile(tile, [input_shape[-3], input_shape[-2]]), (1, input_shape[-3]*2, input_shape[-2]*2, 1))\n",
    "\n",
    "class IsotropicLowpassFilteredUpsampleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, cutoff, kernel_size):\n",
    "        super(IsotropicLowpassFilteredUpsampleLayer, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        assert self.kernel_size % 2 == 0, \"kernel_size must be even\"\n",
    "        self.upsampling = tf.keras.layers.UpSampling2D(size = (2, 2), interpolation='nearest')\n",
    "        self.multiply = tf.keras.layers.Multiply()\n",
    "        #self.zeropadding = tf.keras.layers.ZeroPadding2D(padding = ((0, 1), (0, 1)))  # not needed for input even -> output even\n",
    "        self.kernel_prototype = windowed_circular_lowpass_kernel(cutoff, kernel_size)\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.multiplication_tensor = get_upsample_multiplication_tensor(input_shape)\n",
    "        self.filtering = tf.keras.layers.DepthwiseConv2D(self.kernel_size, trainable=False, use_bias=False, padding='same', weights=[channeled_kernel(self.kernel_prototype, input_shape[-1])])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.upsampling(inputs)\n",
    "        x = self.multiply([x, self.multiplication_tensor])\n",
    "        #x = self.zeropadding(x)  # not needed for input even -> output even\n",
    "        x = self.filtering(x)\n",
    "        return x    \n",
    "    \n",
    "print(\"Test input:\")\n",
    "input_shapes = (aa_odd_kernel_size + 2, aa_odd_kernel_size + 2, 3)\n",
    "print(input_shapes)\n",
    "eye = tf.repeat(tf.expand_dims(tf.repeat(tf.expand_dims(tf.eye(input_shapes[0], input_shapes[1]), -1), repeats = input_shapes[2], axis = -1), 0), repeats = batch_size, axis = 0)\n",
    "print(eye)\n",
    "plt.imshow(eye[0])\n",
    "plt.show()\n",
    "\n",
    "def TestModel(input_shapes):\n",
    "    inputs = tf.keras.Input(input_shapes)\n",
    "    outputs = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)    \n",
    "    return model\n",
    "\n",
    "print(\"Isotropic lowpass filtered:\")\n",
    "model = TestModel(input_shapes)\n",
    "output = model(eye)\n",
    "plt.imshow(output[0])\n",
    "plt.show()\n",
    "\n",
    "def TestModel(input_shapes):\n",
    "    inputs = tf.keras.Input(input_shapes)\n",
    "    outputs = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)    \n",
    "    return model\n",
    "\n",
    "print(\"Isotropic lowpass filtered upsampled:\")\n",
    "model = TestModel(input_shapes)\n",
    "output = model(eye)\n",
    "plt.imshow(output[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f73bdd",
   "metadata": {},
   "source": [
    "## Get a batch from the dataset by recropping photos\n",
    "This should be done in the beginning of each epoch by calling RandomCropper.recrop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCropper:\n",
    "    def __init__(self, dataset, first_seed = None):\n",
    "        if first_seed is None:\n",
    "            first_seed = int(str(int((datetime.utcnow() - datetime(1970, 1, 1)).total_seconds()*1_000_000))[::-1][:16])\n",
    "        self.dataset_seeded = dataset.enumerate(first_seed)\n",
    "    \n",
    "    def recrop(self, size):\n",
    "        cropped_dataset = self.dataset_seeded.map(lambda seed, image: tf.image.stateless_random_crop(image, (size, size, 3), [seed, 0]), num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        self.dataset_seeded = self.dataset_seeded.map(lambda seed, image: (seed + self.dataset_seeded.cardinality(), image), num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "        return cropped_dataset\n",
    "    \n",
    "train_dataset_cropper = RandomCropper(train_dataset)\n",
    "print(\"First recrop, first item:\")\n",
    "iterator = iter(train_dataset_cropper.recrop(train_image_cropped_size))\n",
    "plt.imshow((next(iterator) + 1)/2)\n",
    "plt.show()\n",
    "print(\"Second recrop, first item:\")\n",
    "iterator = iter(train_dataset_cropper.recrop(train_image_cropped_size))\n",
    "plt.imshow((next(iterator) + 1)/2)\n",
    "plt.show()\n",
    "print(\"Second recrop, second item:\")\n",
    "plt.imshow((next(iterator) + 1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb309349",
   "metadata": {},
   "source": [
    "## Generator model\n",
    "Define the generator network, parameterized by input image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c547c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(input_size, nonlinearity, initializer):      \n",
    "    inputs = tf.keras.Input(shape = (input_size, input_size, 1), name = \"input\")\n",
    "  \n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(inputs)\n",
    "  \n",
    "    #-----------------First down\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    # Two activations, huh?\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "\n",
    "    #-----------------Second down\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    \n",
    "    #-----------------Third down\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "\n",
    "    #----------------- Fourth down\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "\n",
    "    #----------------- Fifth down\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(128, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "\n",
    "    #----------------- Fifth last up\n",
    "\n",
    "    x = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)    \n",
    "\n",
    "    #----------------- Fourth last up\n",
    "\n",
    "    x = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)    \n",
    "    \n",
    "    #----------------- Third last up\n",
    "\n",
    "    x = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)    \n",
    "    \n",
    "    #----------------- Second last up\n",
    "\n",
    "    x = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "\n",
    "    #-----------------Last up\n",
    "\n",
    "    x = IsotropicLowpassFilteredUpsampleLayer(np.pi/oversampling, aa_even_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(3, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(3, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Activation(\"tanh\")(x)\n",
    "    x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "    \n",
    "    # Crop the center\n",
    "    \n",
    "    #x = tf.keras.layers.CenterCrop(input_size//2, input_size//2)(x)\n",
    "\n",
    "    return  tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_image_cropped_size\n",
    "initializer = tf.keras.initializers.RandomUniform(-0.1, 0.1)\n",
    "generator = Generator(input_size, \"relu\", \"glorot_uniform\")\n",
    "generator.build((4, input_size, input_size, 1))\n",
    "#Added model diagram\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate, normalize for display, again\n",
    "generator_output = generator(tf.random.uniform((4, input_size, input_size, 1), minval=0, maxval=None), training = True)[0].numpy()\n",
    "print(np.amin(generator_output, axis = (0, 1)))\n",
    "print(np.amax(generator_output, axis = (0, 1)))\n",
    "generator_output -= np.amin(generator_output, axis = (0, 1))\n",
    "generator_output /= np.amax(generator_output, axis = (0, 1))\n",
    "plt.imshow(generator_output)\n",
    "plt.show()\n",
    "\n",
    "# Generate, display\n",
    "generator_output = generator(tf.random.uniform((4, input_size, input_size, 1), minval=0, maxval=None), training = True)[0].numpy()\n",
    "plt.imshow(generator_output)\n",
    "plt.show()\n",
    "\n",
    "# Generate, normalize for display, again\n",
    "generator_output = generator(tf.random.uniform((4, input_size, input_size, 1), minval=0, maxval=None), training = True)[0].numpy()\n",
    "generator_output -= np.amin(generator_output, axis = (0, 1))\n",
    "generator_output /= np.amax(generator_output, axis = (0, 1))\n",
    "plt.imshow(generator_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def generator_loss(disc_generated_output, gen_output):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "  return gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(input_size, nonlinearity, initializer):\n",
    "  \n",
    "  tar = tf.keras.layers.Input(shape=[input_size, input_size, 3], name='input')\n",
    "  \n",
    "  x = tar\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  x = tf.keras.layers.Conv2D(8, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = tf.keras.layers.LeakyReLU()(x)\n",
    "  # Two activations, huh?\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  x = tf.keras.layers.Conv2D(16, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  x = tf.keras.layers.Conv2D(32, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_even_kernel_size, strides=2)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  x = tf.keras.layers.Conv2D(64, 5, kernel_initializer=initializer, use_bias=True, padding=\"same\")(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.Activation(nonlinearity)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size, strides=1)(x)\n",
    "  x = IsotropicLowpassFilterLayer(np.pi/oversampling, aa_odd_kernel_size)(x)\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)  # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=tar, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674810b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.RandomUniform(-0.1, 0.1)\n",
    "discriminator = Discriminator(input_size, \"relu\", \"glorot_uniform\")\n",
    "discriminator.build((batch_size, input_size, input_size, 3))\n",
    "#Added model diagram\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = discriminator(generator_output[tf.newaxis, ...], training=True)\n",
    "plt.imshow(disc_out[0, ..., -1], cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer():\n",
    "  #optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.5, beta_2=0.99, epsilon=1e-07)\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "  return optimizer\n",
    "\n",
    "generator_optimizer = select_optimizer()\n",
    "discriminator_optimizer = select_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a28ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The structure for batching the randomly cropped elements\n",
    "dataset = train_dataset_cropper.recrop(train_image_cropped_size)\n",
    "tensor_list = []\n",
    "for i in dataset.take(-1):\n",
    "  tensor_list.append(i)\n",
    "tensor_list = tf.convert_to_tensor(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2787fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 100 # How many epochs to skip between data display and saving\n",
    "\n",
    "checkpoint_dir = './training_checkpoints_gan'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "def checkpoint_save(epoch, inEpochs = 100):\n",
    "  if (epoch + 1) % inEpochs == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "def generate_images(generator, save = False, epoch = 0): # the training parameter is for batchnorm, in case it is used\n",
    "  z = tf.random.uniform((batch_size, input_size, input_size, 1), minval=0, maxval=None)\n",
    "  prediction = generator(z, training=True)\n",
    "  plt.figure(figsize = (7, 7))\n",
    "  first = prediction[0, ...]\n",
    "  display_list = [first]\n",
    "  title = ['Network output']\n",
    "  \n",
    "  for i in range(1):\n",
    "    plt.subplot(1, 1, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(display_list[i])\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "@tf.function\n",
    "def train_step(z, target, epoch):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(z, training=True)\n",
    "\n",
    "    disc_real_output = discriminator(target, training=True)\n",
    "    disc_generated_output = discriminator(gen_output, training=True)\n",
    "\n",
    "    gen_gan_loss = generator_loss(disc_generated_output, gen_output)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "    generator_gradients = gen_tape.gradient(gen_gan_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "    \n",
    "  \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                            generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                discriminator.trainable_variables))\n",
    "\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "\n",
    "def fit(epochs, dataset):\n",
    "  for epoch in range(epochs + 1):\n",
    "    checkpoint_save(epoch)\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    if epoch > 0:\n",
    "      z = tf.random.uniform((batch_size, input_size, input_size, 1), minval=0, maxval=None)\n",
    "      dataset = train_dataset_cropper.recrop(train_image_cropped_size)\n",
    "      tensor_list = []\n",
    "      for i in dataset.take(-1):\n",
    "        tensor_list.append(i)\n",
    "      target = tf.convert_to_tensor(tensor_list)\n",
    "      train_step(z, target, epoch)\n",
    "      #display.clear_output(wait=True)\n",
    "    elapsed = time.time() - start\n",
    "    for target in dataset.take(1):\n",
    "      generate_images(generator) \n",
    "       #training = ?\n",
    "      if epoch == 0:\n",
    "          print(\"....\")\n",
    "      else:\n",
    "          print('Training epoch {}, took {} s\\n'.format(epoch, elapsed))\n",
    "\n",
    "  checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in dataset.take(1):\n",
    "  generate_images(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ec7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/\"\n",
    "im_dir = \"images/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "os.makedirs(im_dir)\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --host localhost --port 6221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7418127",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "fit(EPOCHS, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbfaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
