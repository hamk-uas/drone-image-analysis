{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bd24dd",
   "metadata": {},
   "source": [
    "## Cropping for the experimental anti-aliasing downsample layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb07e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4219b",
   "metadata": {},
   "source": [
    "## Set where image is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cab2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to(save = \"locally\"):\n",
    "  if save == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd drive/MyDrive/Colab Notebooks/drones\n",
    "  elif save == \"ssd\":\n",
    "    os.chdir(\"D:/GanNoMask\")\n",
    "\n",
    "save_to(\"ssd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7244f",
   "metadata": {},
   "source": [
    "## Crop input the image to square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761b0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3024 #Select the maximum available square dimension\n",
    "im = Image.open(\"C:/Users/romat/Desktop/somefolder/IMG_2120.png\")\n",
    "im = im.crop((0, 0, h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d12b54",
   "metadata": {},
   "source": [
    "## Resize the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9056cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = 1314 # We set the size to 511 instead of 512 so we can then cut the middle portion of it without mixing up the pixels in the 445x445 image.\n",
    "im = im.resize((h1, h1))\n",
    "im.save(\"testinput.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5b0b8",
   "metadata": {},
   "source": [
    "## Take the middle square of the input image to match the Unet output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425adb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = 266 # Plus 8 to compensate for filtering\n",
    "#.convert(\"L\")\n",
    "im.crop(((h1-h2)/2, (h1-h2)/2, (h1+h2)/2, (h1+h2)/2)).save(\"testtarget.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b46271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
